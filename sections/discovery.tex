\section{Discovering \pdeclare Models from Event Logs}
\label{sec:discovery}
We now show that \pdeclare models can be discovered from event data using, off-the-shelf, already existing techniques, with a quite interesting guarantee: that the discovered model is always consistent.
%
We use the standard notation $[\cdot]$ for multisets, and use superscript numbers to identify the multiplicity of an element in the multiset.

A plethora of different algorithms have been devised to discover \declare models from event data \cite{LMMR07,MaCV12,CiccioM15,DBLP:conf/caise/SchonigRCJM16}. In general, the vast majority of these algorithms adopt the following approach to discovery:
\begin{inparaenum}[(1)] 
\item  Candidate constraints are generated by analyzing the activities contained in the log. 
\item For each constraint, its \emph{support} is computed as the fraction of traces in the log where the constraint holds.
\item Candidate constraints are filtered, retaining only those whose support exceeds a given threshold. 
\item Further filters (e.g., considering the ``relevance'' of a constraint \cite{DMMM18}) are applied. 
\item The overall model is checked for satisfiability, operating with different strategies if it is not; this is necessary since constraints with high support, but less than $1$, may actually conflict with each other \cite{DMMM17}.
\end{inparaenum}
%
In this procedure, the notion of support is formalized as follows.
\begin{definition}
The \emph{support} of an \LTLf constraint $\varphi$ in an event log $\mathcal{L} = [\tau_1, \dots,  \tau_n]$ is
\begin{equation*}
\mathit{supp}_{\mathcal{L}}(\varphi) = \frac{\vert\mathcal{L}_{\varphi}\vert}{\vert \mathcal{L}\vert}, \text{ where }\mathcal{L}_{\varphi} = [\tau \in \mathcal{L} \mid \tau \models \varphi]
\end{equation*}
\end{definition}
%
By the semantics of probabilistic constraints, we can adopt this approach off-the-shelf to discover \pdeclare constraints: \emph{we just use the constraint support as its associated probability, with operator $=$}. In other words, if $\varphi$ is discovered with support $p$, we turn it into the probabilistic constraint $\tup{\varphi,p}$. When doing so, we can also relax step (3), e.g., to retain constraints with a very low support, implying that their negated versions have a very high support.

\begin{example}
  Consider $\L = [\tup{\activity{close},\activity{acc}}^7,\tup{\activity{close},\activity{ref}}^2,\tup{\activity{close},\activity{acc},\activity{ref}}^1]$, capturing the evolution of 10 orders, 7 of which have been closed and then accepted, 2 of which have been closed and then refused, and 1 of which has been closed, then accepted, then refused. The support of constraint \constraint{response}(\activity{close},\activity{acc}) is $8/10 = 0.8$, witnessing that 8 traces satisfy such a constraint, whereas 2 violate it. This corresponds exactly to the interpretation of probability $0.8$ for the probabilistic \constraint{response}(\activity{close},\activity{acc}) constraint in Figure~\ref{fig:scenarios}. More in general, the entire \pdeclare model of Figure~\ref{fig:scenarios} can be discovered from $\L$ by considering the 6 constraints contained in that model and their corresponding support over $\L$.
\end{example}

A second key observation is that once this procedure is used to discover \pdeclare constraints, step (5) is unnecessary: the overall discovered model is in fact guaranteed to be satisfiable (in our probabilistic sense).
%
\begin{theorem}
Let $\Sigma$ be a set of activities, $\mathcal{L}$ be an event log over $\Sigma$,
and
$\mathcal{C}=\set{\tup{\varphi_1,p_1},\ldots,\tup{\varphi_n,p_n}}$ be a set of probabilistic constraints discovered from $\mathcal{L}$, such that for each $i \in \set{1,\ldots,n}$, $p_i = \mathit{supp}_{\mathcal{L}}(\varphi_i)$.
 The \pdeclare model $\tup{\Sigma,\mathcal{C}}$ is satisfiable.
\end{theorem}
%
\begin{proof}
Recall that $\tup{\Sigma,\mathcal{C}}$ is satisfiable if its corresponding \PLTLz formula
$\Phi:=\{\prob{p_1}\varphi_1,\ldots,\prob{p_n}\varphi_n\}$ is satisfiable.
To show this, we simply use $\mathcal{L}$ to build a model of $\Phi$.
%
For every set $I\subseteq \{1,\ldots,n\}$, let
$\varphi_I$ be the $\text{LTL}_f$ formula
\[
\varphi_I := \bigwedge_{i\in I} \varphi_i \land \bigwedge_{i\notin I}\neg\varphi_i,
\]
and let $\mathcal{L}_I$ be the sublog of $\mathcal{L}$ containing all the traces that satisfy $\varphi_I$. Note
that the sublogs $\mathcal{L}_I$ form a partition of $\mathcal{L}$; that is, every trace appears in exactly one
such $\mathcal{L}_I$.
%%
For each $I$ such that $\mathcal{L}_I$ is not empty, choose a representative $t_I\in\mathcal{L}_I$ and let
$p_I:=\frac{\vert \mathcal{L}_I \vert}{\vert \mathcal{L} \vert}$ be the fraction of traces that belong to $\mathcal{L}_I$. 
We build a stochastic language $\rho$ by setting $\rho(t_I)=p_I$ for each $I$ such that $\mathcal{L}_I\not=\emptyset$
and $\rho(\tau)=0$ for all other traces. We need to show that $\rho$ satisfies $\mathcal{C}$.
%%
Consider a constraint $\left<\varphi,p\right>\in\mathcal{C}$; we need to show that $\sum_{\tau\models\varphi}\rho(\tau)=p$.
Note that by construction, $\sum_{\tau\models\varphi}\rho(\tau)=\sum_{t_I\models\varphi}p_I$ and
since $\mathcal{L}_I$ form a partition the latter is in fact the fraction of traces that satisfy
$\varphi$. On the other hand, $p$ is also the
support of $\varphi$; that is, the proportion of traces satisfying $\varphi$. Hence, both values are equal, and $\rho$
satisfies the \pdeclare model.
\qed
\end{proof}
By this theorem, probabilistic constraints can be discovered in a \emph{purely local} way, having the guarantee that they will never conflict with each other. Obviously, non-local filters can still prove useful to prune implied constraints and select the most relevant ones.
Also, note that the probabilities of the discovered constraints can be easily adjusted when new traces are added to the log, by incrementally recomputing the support values after checking how many new traces satisfy the various constraints.

%The main open question related to the discovery of probabilistic constraints, which we intend to tackle in future work, is to determine when to stop the discovery procedure, and what is the impact of retaining constraints with various degrees of support in terms of over/under-fitting. 